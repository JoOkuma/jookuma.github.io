[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m currently bioimage scientist at the Royerlab at CZ Biohub. I obtained my MSc in Computer Science and BSc in Statistics from the University of Campinas, Brazil. During that time, I spent four wonderful years doing research at LIDS under the supervision of Prof. Alexandre Falcão. In 2019-2020, I was fortunate enough to do a winter research internship at LIGM under the supervision of Prof. Laurent Najman.\nFeel free to reach me at jordao.bragantini@gmail.com.\n","date":1611187200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611187200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jookuma.github.io/author/jordao-bragantini/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jordao-bragantini/","section":"authors","summary":"I\u0026rsquo;m currently bioimage scientist at the Royerlab at CZ Biohub. I obtained my MSc in Computer Science and BSc in Statistics from the University of Campinas, Brazil. During that time, I spent four wonderful years doing research at LIDS under the supervision of Prof.","tags":null,"title":"Jordão Bragantini","type":"authors"},{"authors":["Jordão Bragantini","Alexandre Falcão","Laurent Najman"],"categories":null,"content":"","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"e0ccb9f9ce8ac1c49e9e8c026f07a713","permalink":"https://jookuma.github.io/publication/rethinking/","publishdate":"2021-01-21T11:45:06.779109Z","relpermalink":"/publication/rethinking/","section":"publication","summary":"Despite the progress of interactive image segmentation methods, high-quality pixel-level annotation is still time-consuming and laborious --- a bottleneck for several deep learning applications. We take a step back to propose interactive and simultaneous segment annotation from multiple images guided by feature space projection and optimized by metric learning as the labeling progresses. This strategy is in stark contrast to existing interactive segmentation methodologies, which perform annotation in the image domain. We show that our approach can surpass the accuracy of state-of-the-art methods in foreground segmentation datasets: iCoSeg, DAVIS, and Rooftop. Moreover, it achieves 91.5% accuracy in a known semantic segmentation dataset, Cityscapes, being 74.75 times faster than the original annotation procedure. The supplementary material presents additional qualitative results and video demonstrations.","tags":null,"title":"Rethinking Interactive Image Segmentation: Feature Space Annotation","type":"publication"},{"authors":["Jordão Bragantini","Bruno Moura","Alexandre Xavier Falcão","Fábio A. M. Cappabianco"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"383db5d06c3c3d70b8ce754f2d3b6e55","permalink":"https://jookuma.github.io/publication/grabber/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/grabber/","section":"publication","summary":"Interactive image segmentation has considerably evolved from techniques that do not learn the parameters of the model to methods that pre-train a model and adapt it from user inputs during the process. However, user control over segmentation still requires significant improvements to avoid that corrections in one part of the object cause errors in other parts. We address this problem by presenting Grabber --- a tool to improve convergence (user control) in interactive image segmentation. Grabber is thought to complete segmentation of some other initial method. From a given segmentation mask, Grabber quickly estimates anchor points in one orientation along the boundary of the mask and delineates an optimum contour constrained to pass through those points. The user can control the process by adding, removing, and moving anchor points. Grabber can also explore object properties from the initial coarse segmentation to improve boundary delineation. We integrate Grabber with two recent methods, a region-based approach and a pixel classification method based on deep neural networks. Extensive experiments with robot users on two datasets show in both cases that Grabber can significantly improve convergence, with faster delineation, higher effectiveness, and less user effort. The code of Grabber is available at https://github.com/LIDS-UNICAMP/grabber .","tags":["Interactive Image Segmentation"],"title":"Grabber: A Tool to Improve Convergence in Interactive Image Segmentation","type":"publication"},{"authors":["Samuel Botter Martins","Jordão Bragantini","Alexandre Xavier Falcão","Clarissa Lin Yasuda"],"categories":null,"content":"","date":1566086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566086400,"objectID":"16bc37408706e94adf27efefd2c41101","permalink":"https://jookuma.github.io/publication/ada-pro/","publishdate":"2019-08-18T00:00:00Z","relpermalink":"/publication/ada-pro/","section":"publication","summary":"Automated segmentation of brain structures (objects) in MR three‐dimensional (3D) images for quantitative analysis has been a challenge and probabilistic atlases (PAs) are among the most well‐succeeded approaches. However, the existing models do not adapt to possible object anomalies due to the presence of a disease or a surgical procedure. Post‐processing operation does not solve the problem, for example, tissue classification to detect and remove such anomalies inside the resulting segmentation mask, because segmentation errors on healthy tissues cannot be fixed. Such anomalies very often alter the shape and texture of the brain structures, making them different from the appearance of the model. In this paper, we present an effective and efficient adaptive probabilistic atlas, named AdaPro, to circumvent the problem and evaluate it on a challenging task — the segmentation of the left hemisphere, right hemisphere, and cerebellum, without pons and medulla, in 3D MR‐T1 brain images of Epilepsy patients. This task is challenging due to temporal lobe resections, artifacts, and the absence of contrast in some parts between the structures of interest.","tags":["Medical Image Segmentation"],"title":"An adaptive probabilistic atlas for anomalous brain segmentation in MR images","type":"publication"},{"authors":["Jordão Bragantini","Samuel Botter Martins","Cesar Castelo-Fernandez","Alexandre Xavier Falcão"],"categories":null,"content":"","date":1551571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551571200,"objectID":"76a4e37863ba30b892b5e969b5c93dda","permalink":"https://jookuma.github.io/publication/dyn-tree/","publishdate":"2019-03-03T00:00:00Z","relpermalink":"/publication/dyn-tree/","section":"publication","summary":"Image segmentation methods have been actively investigated, being the graph-based approaches among the most popular for object delineation from seed nodes. In this context, one can design segmentation methods by distinct choices of the image graph and connectivity function—i.e., a function that measures how strongly connected are seed and node through a given path. The framework is known as Image Foresting Transform (IFT) and it can define by seed competition each object as one optimum-path forest rooted in its internal seeds. In this work, we extend the general IFT algorithm to extract object information as the trees evolve from the seed set and use that information to estimate arc weights, positively affecting the connectivity function, during segmentation. The new framework is named Dynamic IFT (DynIFT) and it can make object delineation more effective by exploiting color, texture, and shape information from those dynamic trees. In comparison with other graph-based approaches from the state-of-the-art, the experimental results on natural images show that DynIFT-based object delineation methods can be significantly more accurate.","tags":["Interactive Image Segmentation"],"title":"Graph-Based Image Segmentation Using Dynamic Trees","type":"publication"},{"authors":["Alexandre Xavier Falcão","Jordão Bragantini"],"categories":null,"content":"","date":1550880000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550880000,"objectID":"62e1ebf7893f0e9cc18fab62f10b69a2","permalink":"https://jookuma.github.io/publication/role-opt-con/","publishdate":"2019-02-23T00:00:00Z","relpermalink":"/publication/role-opt-con/","section":"publication","summary":"Image segmentation is one of the most investigated research topics in Computer Vision and yet presents challenges due to the difficulty of modeling all possible appearances of objects in images. In this sense, it is important to investigate methods that can learn object information before and during delineation. This paper addresses the problem by exploiting optimum connectivity between image elements (pixels and superpixels) in the image domain and feature space to improve segmentation. The study uses the Image Foresting Transform (IFT) framework to explain and implement all methods and describes some recent advances related to superpixel and object delineation. It provides a guideline to learn prior object information from the target image only based on seed pixels, superpixel clustering, and classification, evaluates the impact of using object information in several connectivity-based delineation methods using the segmentation by a deep neural network as baseline, and shows the potential of a new paradigm, namely Dynamic Trees, to learn object information from the target image only during delineation.","tags":["Interactive Image Segmentation"],"title":"The Role of Optimum Connectivity in Image Segmentation: Can the Algorithm Learn Object Information During the Process?","type":"publication"}]